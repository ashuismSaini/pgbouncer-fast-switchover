diff --git a/src/server.c b/src/server.c
index c6e5efe..ef0cdb3 100644
--- a/src/server.c
+++ b/src/server.c
@@ -27,6 +27,122 @@
 
 #define ERRCODE_CANNOT_CONNECT_NOW "57P03"
 
+bool routing_traffic_to_target_complete = false;
+
+/**
+ * Extracts and processes query result data from a packet into a tab-separated string.
+ *
+ * This function performs the following steps:
+ * 1. Reads the number of columns from the packet header
+ * 2. Calculates total required buffer length in first pass
+ * 3. Allocates memory for output string
+ * 4. Copies column data with tab separators in second pass
+ *
+ * The returned string format is: col1\tcol2\tcol3...\tcolN\0
+ *
+ * @param pkt       Pointer to PktHdr structure containing raw packet data
+ *                  Must contain valid column count and column data
+ *
+ * @return          On success: Pointer to newly allocated string containing tab-separated column data
+ *                  On failure: NULL (with error logged)
+ *                  Caller must free the returned string
+ *
+ * @note           Function will return NULL and log error if:
+ *                 - Cannot read column count
+ *                 - Zero columns in packet
+ *                 - Cannot read column lengths or data
+ *                 - Memory allocation fails
+ *                 - Final position doesn't match calculated length
+ *
+ * @warning        The returned string must be freed by the caller to avoid memory leaks
+ */
+
+static char *query_data(PktHdr *pkt)
+{
+	uint16_t columns;
+	uint32_t length;
+	const char *data;
+	char *output = NULL;
+	size_t total_length = 0;
+	size_t pos = 0;
+	int i;
+	struct MBuf tmp_buf;
+	const uint8_t *dummy;
+
+	/* Get number of columns */
+	if (!mbuf_get_uint16be(&pkt->data, &columns)) {
+		log_error("could not get packet column count");
+		return NULL;
+	}
+
+	if (columns == 0) {
+		log_error("zero columns in packet");
+		return NULL;
+	}
+
+	/* First pass: calculate total length needed */
+	mbuf_copy(&pkt->data, &tmp_buf);  /* Create a copy of the buffer */
+	for (i = 0; i < columns; i++) {
+		if (!mbuf_get_uint32be(&tmp_buf, &length)) {
+			log_error("could not get column %d length", i);
+			return NULL;
+		}
+
+		total_length += length;
+
+		if (!mbuf_get_bytes(&tmp_buf, length, &dummy)) {
+			log_error("could not skip column %d data", i);
+			return NULL;
+		}
+	}
+
+	/* Account for tabs between columns (columns - 1) and 1 null terminator */
+	total_length += (columns - 1) + 1;
+
+	/* Allocate buffer */
+	output = malloc(total_length);
+	if (output == NULL) {
+		log_error("malloc failed: no memory in query_data");
+		return NULL;
+	}
+
+	/* Second pass: actually fetch the data */
+	for (i = 0; i < columns; i++) {
+		if (!mbuf_get_uint32be(&pkt->data, &length)) {
+			log_error("could not get column %d length (second pass)", i);
+			free(output);
+			return NULL;
+		}
+
+		if (!mbuf_get_chars(&pkt->data, length, &data)) {
+			log_error("could not get column %d data (second pass)", i);
+			free(output);
+			return NULL;
+		}
+
+		/* Copy column data */
+		memcpy(output + pos, data, length);
+		pos += length;
+
+		/* Add separator (tab or null terminator) */
+		if (i < columns - 1) {
+			output[pos++] = '\t';
+		} else {
+			output[pos++] = '\0';  /* final null terminator */
+		}
+	}
+
+	if (pos != total_length) {
+		free(output);
+		fatal("final position (%zu) does not match calculated total_length (%zu)", pos, total_length);
+	}
+
+	log_debug("Extracted data: [%s], total_length: %zu, final_pos: %zu", output, total_length, pos);
+
+	return output;
+}
+
+
 static bool load_parameter(PgSocket *server, PktHdr *pkt, bool startup)
 {
 	const char *key, *val;
@@ -122,6 +238,12 @@ static bool handle_server_startup(PgSocket *server, PktHdr *pkt)
 	const char *msg;
 	bool res = false;
 	const uint8_t *ckey;
+	char *data = NULL;
+	char *hostname = NULL;
+	char *endpoint = NULL;
+	char *role = NULL;
+	char *port_str = NULL;
+	int port_num = 0;
 
 	if (incomplete_pkt(pkt)) {
 		disconnect_server(server, true, "partial pkt in login phase");
@@ -133,12 +255,16 @@ static bool handle_server_startup(PgSocket *server, PktHdr *pkt)
 		switch (pkt->type) {
 		case PqMsg_ReadyForQuery:
 		case PqMsg_ParameterStatus:
+		case PqMsg_DataRow:
 			/* handle them below */
 			break;
 
 		case PqMsg_ErrorResponse:
 			/* log & ignore errors */
 			log_server_error("S: error while executing exec_on_query", pkt);
+			// require topology table to exist in the cluster if using
+			if (fast_switchover)
+				fatal("does the topology table exist?");
 		/* fallthrough */
 		default:	/* ignore rest */
 			sbuf_prepare_skip(sbuf, pkt->len);
@@ -152,6 +278,71 @@ static bool handle_server_startup(PgSocket *server, PktHdr *pkt)
 		disconnect_server(server, true, "unknown pkt from server");
 		break;
 
+	case PqMsg_DataRow:
+		if (fast_switchover && server->pool->db->topology_query && server->pool->initial_writer_endpoint) {
+			data = query_data(pkt);
+			if (data) {
+				char *pointer_to_data = data;
+				endpoint = strsep(&pointer_to_data, "\t");
+				/*
+				 * In a Blue-Green deployment, the port and role are retrieved using the topology query.
+				 * When PgBouncer is configured with the fast switchover feature enabled for Blue-Green deployment,
+				 * it expects valid role and port values. If valid values are not found, PgBouncer will crash.
+				 */
+				if (server->pool->db->recovery_query) {
+					role = strsep(&pointer_to_data, "\t");
+					port_str = strsep(&pointer_to_data, "\t");
+					if (role == NULL || port_str == NULL) {
+						free(data);
+						fatal("port or role cannot be null while using the Blue Green fast switchover, port: %s, role: %s",
+							port_str ? port_str : "NULL", role ? role : "NULL");
+					}
+					port_num = atoi(port_str);
+					if (port_num <= 0) {
+						free(data);
+						fatal("Invalid port number: %s", port_str);
+					}
+				} else {
+					port_num = server->pool->db->port;
+				}
+				log_debug("got initial data, endpoint: %s, role: %s, port: %d", endpoint ? endpoint : "NULL", role ? role : "NULL", port_num);
+			}
+
+			/* Make a copy of endpoint for hostname */
+			hostname = strdup(endpoint);
+			if (hostname == NULL) {
+				free(data);
+				fatal("strdup: no mem for hostname");
+			}
+
+			if (!strtok(endpoint, ".")) {
+				free(data);
+				free(hostname);
+				fatal("could not parse hostname from: %s", endpoint);
+			} else {
+				PgPool *new_pool = new_pool_from_db(server->pool->db, endpoint, hostname, port_num);
+				if (new_pool) {
+					new_pool->parent_pool = server->pool;
+					new_pool->parent_pool->global_writer = server->pool;
+					new_pool->db->topology_query = strdup(server->pool->db->topology_query);
+					if (server->pool->db->recovery_query) {
+						new_pool->db->recovery_query = strdup(server->pool->db->recovery_query);
+						if (strcmp(role, BLUE_GREEN_DEPLOYMENT_SOURCE) == 0) {
+							new_pool->db->is_source_db = true;
+						}
+					}
+					launch_new_connection(new_pool, true);
+					server->pool->num_nodes++;
+				}
+			}
+
+			free(data);
+			free(hostname);
+		}
+
+		sbuf_prepare_skip(sbuf, pkt->len);
+		return true;
+
 	case PqMsg_ErrorResponse:
 		/*
 		 * If we cannot log into the server, then we drop all clients
@@ -201,7 +392,42 @@ static bool handle_server_startup(PgSocket *server, PktHdr *pkt)
 			if (!res)
 				disconnect_server(server, false, "exec_on_connect query failed");
 			break;
+		} else if (fast_switchover && server->pool->db->topology_query && server->pool->initial_writer_endpoint) {
+			server->exec_on_connect = true;
+			slog_debug(server, "server connect ok, send topology_query: %s", server->pool->db->topology_query);
+			SEND_generic(res, server, PqMsg_Query, "s", server->pool->db->topology_query);
+			if (!res)
+				disconnect_server(server, false, "exec_on_connect query failed");
+			break;
+		} else if (fast_switchover && server->pool->db->recovery_query && routing_traffic_to_target_complete) {
+			/*
+			 * After the switchover is completed, we set 'routing_traffic_to_target_complete' to true in 'handle_server_work'.
+			 * Once DNS resolution is complete for the target instance, the new DNS becomes available for queries.
+			 * Here, we monitor the startup status of the new blue instance and the 'routing_traffic_to_target_complete' flag.
+			 * Once both conditions are met, we disable the fast switchover feature.
+			 */
+			log_debug("Once the switchover is completed for DB : %s, disabling the fast switchover and reverting PgBouncer to standard connection pooling mode.", server->pool->db->name);
+			if (!server->pool->parent_pool) {
+				server->pool->parent_pool = server->pool;
+			}
+			server->pool->parent_pool->global_writer = server->pool;
+			fast_switchover = false;
+			routing_traffic_to_target_complete = false;
+		}
+
+		if (server->pool->db->topology_query && server->pool->initial_writer_endpoint && server->pool->num_nodes < 2) {
+			if (server->pool->db->recovery_query) {
+				/*
+				 * If Blue-Green Deployment fast switchover is configured on an instance/cluster node without actually creating a Blue-Green Deployment, the metadata table will return no nodes.
+				 * In this case, PgBouncer will not crash. Instead, it will disable the fast switchover feature and revert to the standard PgBouncer behavior.
+				 */
+				fast_switchover = false;
+				log_debug("topology_query did not find at least 2 nodes to use Blue Green Deployment fast switchover for DB: '%s'. PgBouncer reverting to standard connection pooling mode.", server->pool->db->name);
+			} else {
+				fatal("topology_query did not find at least 2 nodes to use fast switchover in DB: '%s'. Is the topology table populated with entries?", server->pool->db->name);
+			}
 		}
+		server->pool->initial_writer_endpoint = false;
 
 		/* login ok */
 		slog_debug(server, "server login ok, start accepting queries");
@@ -363,6 +589,7 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 	bool async_response = false;
 	struct List *item, *tmp;
 	bool ignore_packet = false;
+	bool res = false;
 
 	Assert(!server->pool->db->admin);
 
@@ -374,6 +601,15 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 
 	/* pooling decisions will be based on this packet */
 	case PqMsg_ReadyForQuery:
+		/*
+		 * Discard topology data without sending to the client is finished. Resume regular
+		 * client/server communication.
+		 */
+		if (fast_switchover && server->pool->db->topology_query && server->pool->collect_datarows) {
+			server->pool->collect_datarows = false;
+			sbuf_prepare_skip(sbuf, pkt->len);
+			return true;
+		}
 
 		/* if partial pkt, wait */
 		if (!mbuf_get_char(&pkt->data, &state))
@@ -461,6 +697,22 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 		break;
 
 	case PqMsg_CommandComplete:
+		/*
+		 * In the process of discarding topology data without sending to the client.
+		 */
+		if (server->pool->collect_datarows) {
+			sbuf_prepare_skip(sbuf, pkt->len);
+			return true;
+		} else if (fast_switchover && server->pool->db->recovery_query && server->pool->checking_for_new_writer && server->state != SV_TESTED) {
+			/*
+			 * This handles a corner case where the recovery query did not return any data rows for any reason.
+			 * To keep searching for the new writer, we set `checking_for_new_writer` to false for this pool,
+			 * allowing the recovery query to run again through this pool.
+			 */
+			log_debug("handle_server_work: switchover started retrying to get the state of Blue Green deployment, db_name: %s", server->pool->db->name);
+			server->pool->checking_for_new_writer = false;
+		}
+
 		/* ErrorResponse and CommandComplete show end of copy mode */
 		if (server->copy_mode) {
 			slog_debug(server, "COPY finished");
@@ -545,6 +797,37 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 	/* data packets, there will be more coming */
 	case PqMsg_CopyData:
 	case PqMsg_DataRow:
+		/*
+		 * These are the rows returned from the topology query that are discarded.
+		 */
+		if (server->pool->collect_datarows) {
+			sbuf_prepare_skip(sbuf, pkt->len);
+			return true;
+		} else if (fast_switchover && server->pool->checking_for_new_writer && server->state != SV_TESTED) {
+			char *data = query_data(pkt);
+			/*
+			 * Once the switchover begins, the recovery query will run on the target instance to retrieve the switchover status from the metadata table.
+			 * When the status changes to either SWITCHOVER_IN_POST_PROCESSING or SWITCHOVER_COMPLETED,
+			 * it indicates that the target instance is ready for accepting the writes, and we can safely update the global writer to point to the target instance.
+			 */
+			if (strcmp(data, "f") == 0 || ((strcmp(data, SWITCHOVER_IN_POST_PROCESSING) == 0) || (strcmp(data, SWITCHOVER_COMPLETED) == 0))) {
+				log_debug("handle_server_work: connected to writer (pg_is_in_recovery is '%s'): db_name %s", data, server->pool->db->name);
+
+				if (!server->pool->parent_pool) {
+					server->pool->parent_pool = server->pool;
+				}
+				server->pool->parent_pool->global_writer = server->pool;
+				// new writer has been found, so indicate that we need to refresh the topology.
+				server->pool->refresh_topology = true;
+				if (server->pool->db->recovery_query) {
+					routing_traffic_to_target_complete =  true;
+				}
+			} else {
+				log_debug("handle_server_work: connected to reader (pg_is_in_recovery is '%s'). db_name: %s, Must keep polling until next server.", data, server->pool->db->name);
+			}
+			server->pool->checking_for_new_writer = false;
+			free(data);
+		}
 		break;
 	}
 	server->idle_tx = idle_tx;
@@ -632,7 +915,7 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 			}
 		}
 	} else {
-		if (server->state != SV_TESTED) {
+		if (server->state != SV_TESTED && !server->pool->db->topology_query) {
 			slog_warning(server,
 				     "got packet '%c' from server when not linked",
 				     pkt_desc(pkt));
@@ -640,6 +923,19 @@ static bool handle_server_work(PgSocket *server, PktHdr *pkt)
 		sbuf_prepare_skip(sbuf, pkt->len);
 	}
 
+	/*
+	 * pg_is_in_recovery() finished since we received a ReadyForQuery and refresh_topology is set.
+	 * Mark the pool as needing to collect data rows and send the topology query to the writer.
+	 */
+	if (server->pool->refresh_topology && pkt->type == 'Z') {
+		server->pool->collect_datarows = true;
+		server->pool->refresh_topology = false;
+
+		SEND_generic(res, server, PqMsg_Query, "s", server->pool->db->topology_query);
+		if (!res)
+			disconnect_server(server, false, "exec_on_connect query failed");
+		}
+
 	return true;
 }
 
@@ -754,6 +1050,7 @@ bool server_proto(SBuf *sbuf, SBufEvent evtype, struct MBuf *data)
 	bool res = false;
 	PgSocket *server = container_of(sbuf, PgSocket, sbuf);
 	PgPool *pool = server->pool;
+	PgPool *global_writer = get_global_writer(pool);
 	PktHdr pkt;
 	char infobuf[96];
 
@@ -768,8 +1065,18 @@ bool server_proto(SBuf *sbuf, SBufEvent evtype, struct MBuf *data)
 	case SBUF_EV_RECV_FAILED:
 		if (server->state == SV_ACTIVE_CANCEL)
 			disconnect_server(server, false, "successfully sent cancel request");
-		else
+		else {
+			if (global_writer)
+				clear_global_writer(pool);
+
+			// mark main pool as failed as well (the writer)
+			if (fast_switchover) {
+				pool->last_failed_time = get_cached_time();
+				pool->last_connect_failed = true;
+				server->pool->checking_for_new_writer = false;
+			}
 			disconnect_server(server, false, "server conn crashed?");
+		}
 		break;
 	case SBUF_EV_SEND_FAILED:
 		disconnect_client(server->link, false, "unexpected eof");
@@ -810,6 +1117,10 @@ bool server_proto(SBuf *sbuf, SBufEvent evtype, struct MBuf *data)
 		break;
 	case SBUF_EV_CONNECT_FAILED:
 		Assert(server->state == SV_LOGIN);
+		if (fast_switchover) {
+			pool->last_failed_time = get_cached_time();
+			server->pool->checking_for_new_writer = false;
+		}
 		disconnect_server(server, false, "connect failed");
 		break;
 	case SBUF_EV_CONNECT_OK:
